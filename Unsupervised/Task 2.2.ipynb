{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103cee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64550409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "df_weather = pd.read_csv('/Users/marika/Data Sets/Dataset-weather-prediction-dataset-processed.csv')\n",
    "pleasant_weather = pd.read_csv('/Users/marika/Data Sets/Dataset-Answers-Weather_Prediction_Pleasant_Weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb29829",
   "metadata": {},
   "source": [
    "# Developing an RNN (LSTM) Model for Weather Prediction\n",
    "\n",
    "I am using the Recurrent Neural Network (RNN) model, a Long Short-Term Memory (LSTM) network, over a Convolutional Neural Network (CNN). The key reason for this choice is that RNNs, especially LSTMs, are well-suited for sequential data and time series analysis, which is what weather data typically is.\n",
    "\n",
    "# Why RNN (LSTM) for Weather Prediction?\n",
    "\n",
    "Sequential Data Handling: Weather data is inherently sequential, with patterns and dependencies across time. RNNs, particularly LSTMs, are designed to capture long-term dependencies and trends in sequential data, making them ideal for predicting future weather conditions based on past observations.\n",
    "\n",
    "Temporal Dependencies: Weather patterns often depend on previous conditions. LSTM networks can retain information over longer periods, enabling the model to consider the influence of earlier weather events when making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62983e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop DATE and MONTH from the observations data\n",
    "df_weather_cleaned = df_weather.drop(columns=['DATE', 'MONTH'])\n",
    "\n",
    "# Drop DATE from the predictions data (pleasant_weather dataset)\n",
    "pleasant_weather_cleaned = pleasant_weather.drop(columns=['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4dfe16d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22950 entries, 0 to 22949\n",
      "Columns: 170 entries, DATE to VALENTIA_temp_max\n",
      "dtypes: float64(145), int64(25)\n",
      "memory usage: 29.8 MB\n",
      "None\n",
      "       DATE  MONTH  BASEL_cloud_cover  BASEL_wind_speed  BASEL_humidity  \\\n",
      "0  19600101      1                  7               2.1            0.85   \n",
      "1  19600102      1                  6               2.1            0.84   \n",
      "2  19600103      1                  8               2.1            0.90   \n",
      "3  19600104      1                  3               2.1            0.92   \n",
      "4  19600105      1                  6               2.1            0.95   \n",
      "\n",
      "   BASEL_pressure  BASEL_global_radiation  BASEL_precipitation  \\\n",
      "0           1.018                    0.32                 0.09   \n",
      "1           1.018                    0.36                 1.05   \n",
      "2           1.018                    0.18                 0.30   \n",
      "3           1.018                    0.58                 0.00   \n",
      "4           1.018                    0.65                 0.14   \n",
      "\n",
      "   BASEL_snow_depth  BASEL_sunshine  ...  VALENTIA_cloud_cover  \\\n",
      "0                 0             0.7  ...                     5   \n",
      "1                 0             1.1  ...                     7   \n",
      "2                 0             0.0  ...                     7   \n",
      "3                 0             4.1  ...                     7   \n",
      "4                 0             5.4  ...                     3   \n",
      "\n",
      "   VALENTIA_humidity  VALENTIA_pressure  VALENTIA_global_radiation  \\\n",
      "0               0.88             1.0003                       0.45   \n",
      "1               0.91             1.0007                       0.25   \n",
      "2               0.91             1.0096                       0.17   \n",
      "3               0.86             1.0184                       0.13   \n",
      "4               0.80             1.0328                       0.46   \n",
      "\n",
      "   VALENTIA_precipitation  VALENTIA_snow_depth  VALENTIA_sunshine  \\\n",
      "0                    0.34                    0                4.7   \n",
      "1                    0.84                    0                0.7   \n",
      "2                    0.08                    0                0.1   \n",
      "3                    0.98                    0                0.0   \n",
      "4                    0.00                    0                5.7   \n",
      "\n",
      "   VALENTIA_temp_mean  VALENTIA_temp_min  VALENTIA_temp_max  \n",
      "0                 8.5                6.0               10.9  \n",
      "1                 8.9                5.6               12.1  \n",
      "2                10.5                8.1               12.9  \n",
      "3                 7.4                7.3               10.6  \n",
      "4                 5.7                3.0                8.4  \n",
      "\n",
      "[5 rows x 170 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22950 entries, 0 to 22949\n",
      "Data columns (total 16 columns):\n",
      " #   Column                       Non-Null Count  Dtype\n",
      "---  ------                       --------------  -----\n",
      " 0   DATE                         22950 non-null  int64\n",
      " 1   BASEL_pleasant_weather       22950 non-null  int64\n",
      " 2   BELGRADE_pleasant_weather    22950 non-null  int64\n",
      " 3   BUDAPEST_pleasant_weather    22950 non-null  int64\n",
      " 4   DEBILT_pleasant_weather      22950 non-null  int64\n",
      " 5   DUSSELDORF_pleasant_weather  22950 non-null  int64\n",
      " 6   HEATHROW_pleasant_weather    22950 non-null  int64\n",
      " 7   KASSEL_pleasant_weather      22950 non-null  int64\n",
      " 8   LJUBLJANA_pleasant_weather   22950 non-null  int64\n",
      " 9   MAASTRICHT_pleasant_weather  22950 non-null  int64\n",
      " 10  MADRID_pleasant_weather      22950 non-null  int64\n",
      " 11  MUNCHENB_pleasant_weather    22950 non-null  int64\n",
      " 12  OSLO_pleasant_weather        22950 non-null  int64\n",
      " 13  SONNBLICK_pleasant_weather   22950 non-null  int64\n",
      " 14  STOCKHOLM_pleasant_weather   22950 non-null  int64\n",
      " 15  VALENTIA_pleasant_weather    22950 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 2.8 MB\n",
      "None\n",
      "       DATE  BASEL_pleasant_weather  BELGRADE_pleasant_weather  \\\n",
      "0  19600101                       0                          0   \n",
      "1  19600102                       0                          0   \n",
      "2  19600103                       0                          0   \n",
      "3  19600104                       0                          0   \n",
      "4  19600105                       0                          0   \n",
      "\n",
      "   BUDAPEST_pleasant_weather  DEBILT_pleasant_weather  \\\n",
      "0                          0                        0   \n",
      "1                          0                        0   \n",
      "2                          0                        0   \n",
      "3                          0                        0   \n",
      "4                          0                        0   \n",
      "\n",
      "   DUSSELDORF_pleasant_weather  HEATHROW_pleasant_weather  \\\n",
      "0                            0                          0   \n",
      "1                            0                          0   \n",
      "2                            0                          0   \n",
      "3                            0                          0   \n",
      "4                            0                          0   \n",
      "\n",
      "   KASSEL_pleasant_weather  LJUBLJANA_pleasant_weather  \\\n",
      "0                        0                           0   \n",
      "1                        0                           0   \n",
      "2                        0                           0   \n",
      "3                        0                           0   \n",
      "4                        0                           0   \n",
      "\n",
      "   MAASTRICHT_pleasant_weather  MADRID_pleasant_weather  \\\n",
      "0                            0                        0   \n",
      "1                            0                        0   \n",
      "2                            0                        0   \n",
      "3                            0                        0   \n",
      "4                            0                        0   \n",
      "\n",
      "   MUNCHENB_pleasant_weather  OSLO_pleasant_weather  \\\n",
      "0                          0                      0   \n",
      "1                          0                      0   \n",
      "2                          0                      0   \n",
      "3                          0                      0   \n",
      "4                          0                      0   \n",
      "\n",
      "   SONNBLICK_pleasant_weather  STOCKHOLM_pleasant_weather  \\\n",
      "0                           0                           0   \n",
      "1                           0                           0   \n",
      "2                           0                           0   \n",
      "3                           0                           0   \n",
      "4                           0                           0   \n",
      "\n",
      "   VALENTIA_pleasant_weather  \n",
      "0                          0  \n",
      "1                          0  \n",
      "2                          0  \n",
      "3                          0  \n",
      "4                          0  \n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the data\n",
    "print(df_weather.info())\n",
    "print(df_weather.head())\n",
    "\n",
    "print(pleasant_weather.info())\n",
    "print(pleasant_weather.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98874180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with insufficient data: []\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of missing data in each column\n",
    "missing_data_percent = df_weather.isnull().mean() * 100\n",
    "\n",
    "# Identify columns with more than a threshold percentage of missing data (e.g., 20%)\n",
    "insufficient_data_columns = missing_data_percent[missing_data_percent > 20].index.tolist()\n",
    "\n",
    "print(\"Columns with insufficient data:\", insufficient_data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a851d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns missing data in multiple years: []\n"
     ]
    }
   ],
   "source": [
    "date_data = df_weather.groupby('DATE').count()\n",
    "\n",
    "# Identify columns that have missing data in multiple years\n",
    "columns_missing_multiple_years = date_data.columns[date_data.apply(lambda x: x == 0).sum() > 1].tolist()\n",
    "\n",
    "print(\"Columns missing data in multiple years:\", columns_missing_multiple_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98e53c5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns after dropping: Index(['DATE', 'MONTH', 'BASEL_cloud_cover', 'BASEL_wind_speed',\n",
      "       'BASEL_humidity', 'BASEL_pressure', 'BASEL_global_radiation',\n",
      "       'BASEL_precipitation', 'BASEL_snow_depth', 'BASEL_sunshine',\n",
      "       ...\n",
      "       'VALENTIA_cloud_cover', 'VALENTIA_humidity', 'VALENTIA_pressure',\n",
      "       'VALENTIA_global_radiation', 'VALENTIA_precipitation',\n",
      "       'VALENTIA_snow_depth', 'VALENTIA_sunshine', 'VALENTIA_temp_mean',\n",
      "       'VALENTIA_temp_min', 'VALENTIA_temp_max'],\n",
      "      dtype='object', length=170)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with insufficient data and those missing data in multiple years\n",
    "df_weather_cleaned = df_weather.drop(columns=insufficient_data_columns + columns_missing_multiple_years)\n",
    "\n",
    "print(\"Remaining columns after dropping:\", df_weather_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98bc295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the cleaned dataset\n",
    "df_weather_cleaned.to_csv('/Users/marika/Data Sets/Cleaned_Dataset-weather-prediction-dataset-processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3aef0610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current shape of y: (22950, 16)\n",
      "Total number of elements in y: 367200\n"
     ]
    }
   ],
   "source": [
    "# Check the current shape and size of y\n",
    "print(f\"Current shape of y: {y.shape}\")\n",
    "print(f\"Total number of elements in y: {y.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cfcdbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of y: (22950, 15)\n"
     ]
    }
   ],
   "source": [
    "y = y[:, :15]  # Select only the first 15 columns\n",
    "print(f\"New shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53cc56fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped X shape: (28900, 15, 9)\n"
     ]
    }
   ],
   "source": [
    "# Assuming X initially has the shape (22950, 135)\n",
    "X = X.reshape(-1, 15, 9)  # This reshapes X into (22950, 15, 9)\n",
    "\n",
    "# Verify the shape of X\n",
    "print(f\"Reshaped X shape: {X.shape}\")  # Should output (22950, 15, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9a6ac02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed X shape: (22950, 15, 9)\n"
     ]
    }
   ],
   "source": [
    "# Trim X to match the number of samples in y\n",
    "X = X[:22950]\n",
    "print(f\"Trimmed X shape: {X.shape}\")  # Should be (22950, 15, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41014f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (22950, 15, 9)\n",
      "y shape: (22950, 15)\n"
     ]
    }
   ],
   "source": [
    "# Verify the consistency between X and y\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5f39aa68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9685 - loss: 5067397.5000 - val_accuracy: 1.0000 - val_loss: 12916.3760\n",
      "Epoch 2/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 15396.4961 - val_accuracy: 1.0000 - val_loss: 2048.8726\n",
      "Epoch 3/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2722.9026 - val_accuracy: 1.0000 - val_loss: 519.3423\n",
      "Epoch 4/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 737.6996 - val_accuracy: 1.0000 - val_loss: 179.1896\n",
      "Epoch 5/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 245.6202 - val_accuracy: 1.0000 - val_loss: 95.0421\n",
      "Epoch 6/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 126.8542 - val_accuracy: 1.0000 - val_loss: 77.4529\n",
      "Epoch 7/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 92.1997 - val_accuracy: 1.0000 - val_loss: 74.3129\n",
      "Epoch 8/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 79.8922 - val_accuracy: 1.0000 - val_loss: 77.9536\n",
      "Epoch 9/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 82.5523 - val_accuracy: 1.0000 - val_loss: 81.7704\n",
      "Epoch 10/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 86.3438 - val_accuracy: 1.0000 - val_loss: 87.9593\n"
     ]
    }
   ],
   "source": [
    "# Now split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Continue with model training\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13658f03",
   "metadata": {},
   "source": [
    "The model is achieving perfect accuracy (100%) on both training and validation sets, the loss is increasing exponentially with each epoch. This is an unusual and concerning result, indicating that something is likely wrong with how the model is learning or how the loss is being calculated. The exponentially increasing loss combined with perfect accuracy often suggests:\n",
    "\n",
    "# Numerical Instability: \n",
    "The loss might be computed incorrectly due to large values in the output, possibly due to exploding gradients.\n",
    "\n",
    "# Incorrect Loss Function: \n",
    "The model might be predicting correctly but with very large values, causing the loss function to output large numbers.\n",
    "\n",
    "# Data Imbalance: \n",
    "If the data is highly imbalanced and the model is overfitting, it might achieve high accuracy on a dominant class while poorly predicting others.\n",
    "\n",
    "# Model Overfitting: \n",
    "The model might be overfitting to the training data, memorizing it rather than learning to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "230115af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">495</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_19 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m495\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,783</span> (159.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,783\u001b[0m (159.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,783</span> (159.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,783\u001b[0m (159.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 7136729.0000 - val_accuracy: 1.0000 - val_loss: 51611.3555\n",
      "Epoch 2/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 97633.6484 - val_accuracy: 1.0000 - val_loss: 282229.8125\n",
      "Epoch 3/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 390154.2812 - val_accuracy: 1.0000 - val_loss: 733206.1250\n",
      "Epoch 4/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 915609.1250 - val_accuracy: 1.0000 - val_loss: 1413165.2500\n",
      "Epoch 5/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1683965.2500 - val_accuracy: 1.0000 - val_loss: 2386971.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2717310.5000 - val_accuracy: 1.0000 - val_loss: 3577394.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4063750.5000 - val_accuracy: 1.0000 - val_loss: 5118622.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5738012.5000 - val_accuracy: 1.0000 - val_loss: 6912970.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7649297.5000 - val_accuracy: 1.0000 - val_loss: 9022388.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9895887.0000 - val_accuracy: 1.0000 - val_loss: 11439121.0000\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 1.0000 - loss: 11340473.0000\n",
      "Test Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Implementation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Optional: Add a Conv1D layer for feature extraction (can be skipped if not needed)\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(15, 9)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# LSTM layers\n",
    "model.add(LSTM(units=32, return_sequences=True))  # 1st LSTM layer\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=64, return_sequences=False))  # 2nd LSTM layer\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Flatten the output to feed into dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layers with increasing units in powers of 2\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "# Final dense layer with softmax activation \n",
    "n_classes = len(y[0])  # Assuming y is now (22950, 15)\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e0c8e0",
   "metadata": {},
   "source": [
    "The model is achieving perfect accuracy (100%) on both training and validation sets, the loss is increasing exponentially with each epoch. This is an unusual and concerning result, indicating that something is likely wrong with how the model is learning or how the loss is being calculated. The exponentially increasing loss combined with perfect accuracy often suggests:\n",
    "\n",
    "# Numerical Instability: \n",
    "The loss might be computed incorrectly due to large values in the output, possibly due to exploding gradients.\n",
    "\n",
    "# Incorrect Loss Function: \n",
    "The model might be predicting correctly but with very large values, causing the loss function to output large numbers.\n",
    "\n",
    "# Data Imbalance: \n",
    "If the data is highly imbalanced and the model is overfitting, it might achieve high accuracy on a dominant class while poorly predicting others.\n",
    "\n",
    "# Model Overfitting: \n",
    "The model might be overfitting to the training data, memorizing it rather than learning to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d049a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the Learning Rate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98e53850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Activation Functions\n",
    "model.add(Dense(units=64, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f48e03b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8916 - loss: 20325226.0000 - val_accuracy: 1.0000 - val_loss: 2150174.2500\n",
      "Epoch 2/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2124281.7500 - val_accuracy: 1.0000 - val_loss: 1919011.2500\n",
      "Epoch 3/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1876688.3750 - val_accuracy: 1.0000 - val_loss: 1742337.6250\n",
      "Epoch 4/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1696822.6250 - val_accuracy: 1.0000 - val_loss: 1588381.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1568232.0000 - val_accuracy: 1.0000 - val_loss: 1445203.6250\n",
      "Epoch 6/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1413420.5000 - val_accuracy: 1.0000 - val_loss: 1323461.6250\n",
      "Epoch 7/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1293913.7500 - val_accuracy: 1.0000 - val_loss: 1213098.5000\n",
      "Epoch 8/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1185595.1250 - val_accuracy: 1.0000 - val_loss: 1114598.6250\n",
      "Epoch 9/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1091563.1250 - val_accuracy: 1.0000 - val_loss: 1022120.7500\n",
      "Epoch 10/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1000507.2500 - val_accuracy: 1.0000 - val_loss: 934533.8125\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 1.0000 - loss: 934454.6250\n",
      "Test Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Implementation with Adjustments\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Optional: Conv1D and MaxPooling1D layers\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(15, 9)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# LSTM layers\n",
    "model.add(LSTM(units=32, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=64, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Flatten and Dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64, activation='tanh'))  # Changed activation to tanh\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=32, activation='tanh'))  # Changed activation to tanh\n",
    "\n",
    "# Final layer with softmax\n",
    "n_classes = y.shape[1]\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# Compile with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Re-run the model training\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba70318",
   "metadata": {},
   "source": [
    "# Accuracy: \n",
    "Achieving 100% accuracy on both training and validation data usually suggests the model is overfitting, especially if the loss is not behaving as expected.\n",
    "\n",
    "# Loss: \n",
    "The high loss values, despite the accuracy, suggest that the model outputs are correct in terms of classifying the data but are producing very large or very small numbers before applying the activation function, causing the loss function to compute large values.\n",
    "Possible Causes\n",
    "\n",
    "# Numerical Instability: \n",
    "The large loss values could be due to numerical instability, where the model's predictions are correct in terms of classification but are outputting large logit values before softmax is applied.\n",
    "\n",
    "# Overfitting: \n",
    "The model might be memorizing the training data rather than generalizing, especially if the data is highly imbalanced or the model is too complex.\n",
    "\n",
    "# Activation Function Issues: \n",
    "Even though you have already changed the activation functions and reduced the learning rate, the problem might persist if the model’s output is too extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2709261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further Lower the Learning Rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "02242388",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">495</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_23 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │         \u001b[38;5;34m3,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_24 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m6,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m495\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,855</span> (46.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,855\u001b[0m (46.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,855</span> (46.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,855\u001b[0m (46.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 11496278.0000 - val_accuracy: 1.0000 - val_loss: 1196902.1250\n",
      "Epoch 2/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1372392.1250 - val_accuracy: 1.0000 - val_loss: 587592.1250\n",
      "Epoch 3/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 660929.7500 - val_accuracy: 1.0000 - val_loss: 313563.9062\n",
      "Epoch 4/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 374269.0625 - val_accuracy: 1.0000 - val_loss: 155653.5000\n",
      "Epoch 5/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 191163.6406 - val_accuracy: 1.0000 - val_loss: 82346.5234\n",
      "Epoch 6/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 104364.4688 - val_accuracy: 1.0000 - val_loss: 41692.8477\n",
      "Epoch 7/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 59055.2695 - val_accuracy: 1.0000 - val_loss: 21834.4668\n",
      "Epoch 8/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 30171.0117 - val_accuracy: 1.0000 - val_loss: 12265.7891\n",
      "Epoch 9/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 17796.2520 - val_accuracy: 1.0000 - val_loss: 6330.5835\n",
      "Epoch 10/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9914.4717 - val_accuracy: 1.0000 - val_loss: 3509.7771\n"
     ]
    }
   ],
   "source": [
    "# Implementation with Adjustments\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add Conv1D and MaxPooling1D layers for feature extraction \n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(15, 9)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add LSTM layers while maintaining 3D shape\n",
    "model.add(LSTM(units=16, return_sequences=True))  # Output shape will be (batch_size, timesteps, 16)\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=32, return_sequences=False))  # Output shape will be (batch_size, 32)\n",
    "\n",
    "# Flatten the output before adding Dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Final output layer with softmax activation\n",
    "n_classes = y.shape[1]  \n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model (assuming X_train, y_train, X_test, y_test are defined)\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775af0b3",
   "metadata": {},
   "source": [
    "# Key Observations:\n",
    "\n",
    "Perfect Accuracy: Achieving 100% accuracy on both training and validation sets typically indicates overfitting or that the task is too easy for the model (or that there's a flaw in the data or labels).\n",
    "\n",
    "Decreasing Loss: The loss is decreasing, which is a positive sign, but its high magnitude remains concerning.\n",
    "\n",
    "# Possible Explanations:\n",
    "\n",
    "Numerical Instability: The model might be producing logits with very large values, leading to high loss despite correct predictions.\n",
    "\n",
    "Overfitting: The model could be overfitting to the training data, especially if the validation set is not challenging enough or the data is imbalanced.\n",
    "\n",
    "Data Issues: There might be an issue with the dataset, such as label leakage, where the model has access to the correct labels in some form during training, leading to perfect accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce4c12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower the Learning Rate Further\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62562ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify the Model Further\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=16, input_shape=(15, 9)))\n",
    "model.add(Dense(units=15, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "661dc846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce Regularization\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4a282ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0424 - loss: 55815600.0000 - val_accuracy: 0.1046 - val_loss: 51198432.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1682 - loss: 51472760.0000 - val_accuracy: 0.9444 - val_loss: 43146352.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4354 - loss: 45464172.0000 - val_accuracy: 1.0000 - val_loss: 32247004.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7126 - loss: 36999044.0000 - val_accuracy: 1.0000 - val_loss: 20423814.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8786 - loss: 27511582.0000 - val_accuracy: 1.0000 - val_loss: 11827786.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9409 - loss: 19615868.0000 - val_accuracy: 1.0000 - val_loss: 7041287.5000\n",
      "Epoch 7/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9675 - loss: 14395192.0000 - val_accuracy: 1.0000 - val_loss: 4621751.5000\n",
      "Epoch 8/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 11085595.0000 - val_accuracy: 1.0000 - val_loss: 3361643.7500\n",
      "Epoch 9/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 8822912.0000 - val_accuracy: 1.0000 - val_loss: 2655144.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 7381166.5000 - val_accuracy: 1.0000 - val_loss: 2235304.7500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 1.0000 - loss: 2234947.0000\n",
      "Test Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Simplified model structure\n",
    "model = Sequential()\n",
    "\n",
    "# Conv1D and MaxPooling1D layers (optional)\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(15, 9)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# LSTM layers\n",
    "model.add(LSTM(units=16, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=32, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(units=32, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Final output layer with softmax activation\n",
    "n_classes = y.shape[1]\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# Compile with a very low learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db4c13e",
   "metadata": {},
   "source": [
    "# Key Observations:\n",
    "\n",
    "Improved Accuracy Progression: The accuracy starts low and gradually increases, which is a typical learning curve. However, achieving 100% accuracy suggests the model might still be overfitting.\n",
    "\n",
    "High Loss Values: The loss, although decreasing, remains in the millions, which is not typical for a well-behaved model.\n",
    "\n",
    "# Potential Causes and Solutions:\n",
    "Numerical Instability or Scaling Issues:\n",
    "The large loss values could result from numerical instability, potentially due to the scale of the input features or the initial weight values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d6e45",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b11f3c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of labels (15).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Display the confusion matrix\u001b[39;00m\n\u001b[1;32m     16\u001b[0m disp \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[38;5;241m=\u001b[39mconf_matrix, display_labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16\u001b[39m)])\n\u001b[0;32m---> 17\u001b[0m disp\u001b[38;5;241m.\u001b[39mplot(cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mBlues)\n\u001b[1;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_plot/confusion_matrix.py:181\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.plot\u001b[0;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m colorbar:\n\u001b[1;32m    180\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcolorbar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_, ax\u001b[38;5;241m=\u001b[39max)\n\u001b[0;32m--> 181\u001b[0m ax\u001b[38;5;241m.\u001b[39mset(\n\u001b[1;32m    182\u001b[0m     xticks\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(n_classes),\n\u001b[1;32m    183\u001b[0m     yticks\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(n_classes),\n\u001b[1;32m    184\u001b[0m     xticklabels\u001b[38;5;241m=\u001b[39mdisplay_labels,\n\u001b[1;32m    185\u001b[0m     yticklabels\u001b[38;5;241m=\u001b[39mdisplay_labels,\n\u001b[1;32m    186\u001b[0m     ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue label\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    187\u001b[0m     xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted label\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    188\u001b[0m )\n\u001b[1;32m    190\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylim((n_classes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m))\n\u001b[1;32m    191\u001b[0m plt\u001b[38;5;241m.\u001b[39msetp(ax\u001b[38;5;241m.\u001b[39mget_xticklabels(), rotation\u001b[38;5;241m=\u001b[39mxticks_rotation)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/artist.py:147\u001b[0m, in \u001b[0;36mArtist.__init_subclass__.<locals>.<lambda>\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_autogenerated_signature\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Don't overwrite cls.set if the subclass or one of its parents\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# has defined a set method set itself.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# If there was no explicit definition, cls.set is inherited from\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# the hierarchy of auto-generated set methods, which hold the\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# flag _autogenerated_signature.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Artist\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/artist.py:1227\u001b[0m, in \u001b[0;36mArtist.set\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1224\u001b[0m     \u001b[38;5;66;03m# docstring and signature are auto-generated via\u001b[39;00m\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;66;03m# Artist._update_set_signature_and_docstring() at the end of the\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m     \u001b[38;5;66;03m# module.\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_update(cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, \u001b[38;5;28mself\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/artist.py:1219\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;124;03m    errors as if calling `set`.\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \n\u001b[1;32m   1217\u001b[0m \u001b[38;5;124;03m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_props(\n\u001b[1;32m   1220\u001b[0m         kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{cls.__name__}\u001b[39;00m\u001b[38;5;124m.set() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1221\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{prop_name!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/artist.py:1195\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[1;32m   1193\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1194\u001b[0m                     errfmt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), prop_name\u001b[38;5;241m=\u001b[39mk))\n\u001b[0;32m-> 1195\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(func(v))\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[1;32m   1197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpchanged()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_base.py:73\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_method(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/_api/deprecation.py:297\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     warn_deprecated(\n\u001b[1;32m    293\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/axis.py:2025\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[0;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[1;32m   2022\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2025\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2026\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2027\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2028\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2029\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of labels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2030\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, labels)}\n\u001b[1;32m   2031\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of labels (15)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Step 1: Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 2: Decode predictions and true labels from one-hot encoding\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Step 3: Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[f'Station {i}' for i in range(1, 16)])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d550d12",
   "metadata": {},
   "source": [
    "The confusion matrix appears to have only one class being predicted correctly, with all 4,590 predictions falling into that single class. This indicates that your model is not generalizing well across the 15 different stations and is instead predicting the same class for all inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650042f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
